{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-22 17:18:55--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/2019/week02_classification/comments.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 353358 (345K) [text/plain]\n",
      "Saving to: ‘comments.tsv.2’\n",
      "\n",
      "comments.tsv.2      100%[===================>] 345,08K  1,05MB/s    in 0,3s    \n",
      "\n",
      "2020-03-22 17:18:56 (1,05 MB/s) - ‘comments.tsv.2’ saved [353358/353358]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2019/week02_classification/comments.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should_ban</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The picture on the article is not of the actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Its madness. Shes of Chinese heritage, but JAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck You. Why don't you suck a turd out of my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>God is dead\\nI don't mean to startle anyone bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>THIS USER IS A PLANT FROM BRUCE PERENS AND GRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   should_ban                                       comment_text\n",
       "0           0  The picture on the article is not of the actor...\n",
       "1           1  Its madness. Shes of Chinese heritage, but JAP...\n",
       "2           1  Fuck You. Why don't you suck a turd out of my ...\n",
       "3           1  God is dead\\nI don't mean to startle anyone bu...\n",
       "4           1  THIS USER IS A PLANT FROM BRUCE PERENS AND GRO..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"comments.tsv\", sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['should_ban', 'comment_text'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'купил мужик шляпу ... а она ему как раз ! ! !'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Купил мужик шляпу...а она ему как раз!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['comment_text'].apply(preprocess)\n",
    "y = data['should_ban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the picture on the article is not of the actor...\n",
       "1    its madness . shes of chinese heritage , but j...\n",
       "2    fuck you . why don't you suck a turd out of my...\n",
       "3    god is dead i don't mean to startle anyone but...\n",
       "4    this user is a plant from bruce perens and gro...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "count_vect = TfidfVectorizer()\n",
    "count_vect.fit(X_train)\n",
    "X_tfidf = count_vect.transform(X_train).toarray()\n",
    "X_tfidf_test = count_vect.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_features=5000, stop_words=stop_words)\n",
    "X_count = count_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n",
      "Train: 0.9386666666666666\n",
      "Test: 0.8\n",
      "\n",
      "neighbors\n",
      "Train: 0.872\n",
      "Test: 0.748\n",
      "\n",
      "tree\n",
      "Train: 0.712\n",
      "Test: 0.66\n",
      "\n",
      "forest\n",
      "Train: 1.0\n",
      "Test: 0.724\n",
      "\n",
      "bosting\n",
      "Train: 0.94\n",
      "Test: 0.816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    'logistic': LogisticRegression(),\n",
    "    'neighbors': KNeighborsClassifier(n_neighbors=3, n_jobs=-1),\n",
    "    'tree': DecisionTreeClassifier(max_depth=3),\n",
    "    'forest': RandomForestClassifier(n_jobs=-1),\n",
    "    'bosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    models[name].fit(X_tfidf, y_train)\n",
    "    \n",
    "    predicted_train_y = models[name].predict(X_tfidf)\n",
    "    predicted_test_y = models[name].predict(X_tfidf_test)\n",
    "    \n",
    "    print(name)\n",
    "    print(\"Train:\", accuracy_score(y_train, predicted_train_y))\n",
    "    print(\"Test:\", accuracy_score(y_test, predicted_test_y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000000',\n",
       " '03',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '084080',\n",
       " '09',\n",
       " '0px',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '103',\n",
       " '11',\n",
       " '119',\n",
       " '12',\n",
       " '121',\n",
       " '123',\n",
       " '124',\n",
       " '127',\n",
       " '128',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '131',\n",
       " '134',\n",
       " '136',\n",
       " '14',\n",
       " '141',\n",
       " '142',\n",
       " '144',\n",
       " '147',\n",
       " '15',\n",
       " '153',\n",
       " '154',\n",
       " '159',\n",
       " '16',\n",
       " '163',\n",
       " '164',\n",
       " '17',\n",
       " '170',\n",
       " '173',\n",
       " '174',\n",
       " '176',\n",
       " '177',\n",
       " '18',\n",
       " '180',\n",
       " '184',\n",
       " '185',\n",
       " '186',\n",
       " '19',\n",
       " '192',\n",
       " '193',\n",
       " '194',\n",
       " '1972',\n",
       " '1991',\n",
       " '1992',\n",
       " '1994',\n",
       " '1997',\n",
       " '1998',\n",
       " '1ng',\n",
       " '1px',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2001',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '205',\n",
       " '20th',\n",
       " '21',\n",
       " '212',\n",
       " '217',\n",
       " '22',\n",
       " '220',\n",
       " '221',\n",
       " '224',\n",
       " '226',\n",
       " '227',\n",
       " '228',\n",
       " '23',\n",
       " '230',\n",
       " '235',\n",
       " '24',\n",
       " '240',\n",
       " '246',\n",
       " '249',\n",
       " '25',\n",
       " '251',\n",
       " '254',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '300',\n",
       " '30th',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '38',\n",
       " '39',\n",
       " '3rr',\n",
       " '40',\n",
       " '41',\n",
       " '429',\n",
       " '43',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '500',\n",
       " '51',\n",
       " '52',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '63',\n",
       " '65',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '6d',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '7d',\n",
       " '80',\n",
       " '800',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '844',\n",
       " '85',\n",
       " '86',\n",
       " '88',\n",
       " '8p',\n",
       " '90',\n",
       " '900',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '__',\n",
       " '___',\n",
       " 'aba',\n",
       " 'ability',\n",
       " 'abkhazia',\n",
       " 'able',\n",
       " 'abolish',\n",
       " 'absence',\n",
       " 'absently',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abstain',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'academic',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'achieve',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'adequate',\n",
       " 'admin',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adult',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'afc',\n",
       " 'afd',\n",
       " 'affirmative',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'ages',\n",
       " 'agf',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'aires',\n",
       " 'airing',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akc',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alegre',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloud',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'altered',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'always',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amplitude',\n",
       " 'anal',\n",
       " 'ancient',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'angelfire',\n",
       " 'angle',\n",
       " 'anglo',\n",
       " 'angry',\n",
       " 'ani',\n",
       " 'animal',\n",
       " 'anime',\n",
       " 'ann',\n",
       " 'annon',\n",
       " 'announced',\n",
       " 'annoying',\n",
       " 'anon',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'anti',\n",
       " 'anus',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appears',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approved',\n",
       " 'april',\n",
       " 'arab',\n",
       " 'arbcom',\n",
       " 'arbitrary',\n",
       " 'arbitrators',\n",
       " 'arborsculpture',\n",
       " 'archive',\n",
       " 'archived',\n",
       " 'archives',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arse',\n",
       " 'art',\n",
       " 'arthashastra',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'ashamed',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assange',\n",
       " 'assessed',\n",
       " 'assessment',\n",
       " 'asshole',\n",
       " 'asskrack',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'assure',\n",
       " 'astrological',\n",
       " 'astrology',\n",
       " 'athiest',\n",
       " 'atras',\n",
       " 'attack',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audacity',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'augustine',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'aziz',\n",
       " 'b1tch',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backlash',\n",
       " 'bad',\n",
       " 'badge',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'barnstar',\n",
       " 'barrymore',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basil',\n",
       " 'basing',\n",
       " 'basis',\n",
       " 'bastard',\n",
       " 'bastards',\n",
       " 'batteries',\n",
       " 'bbc',\n",
       " 'beardy',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'bed',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'belive',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bent',\n",
       " 'bernanke',\n",
       " 'bernozz',\n",
       " 'bertiebasset',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beth',\n",
       " 'better',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bhagavad',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bien',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bigoted',\n",
       " 'billy',\n",
       " 'binksternet',\n",
       " 'biographies',\n",
       " 'bios',\n",
       " 'birth',\n",
       " 'bischoff',\n",
       " 'bishops',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'blacks',\n",
       " 'blamed',\n",
       " 'blaming',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'blind',\n",
       " 'bliss',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogs',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blp',\n",
       " 'blue',\n",
       " 'blvd',\n",
       " 'bob',\n",
       " 'bodhidharma',\n",
       " 'body',\n",
       " 'bohemian',\n",
       " 'bon',\n",
       " 'bones',\n",
       " 'bongwarrior',\n",
       " 'book',\n",
       " 'books',\n",
       " 'bootleg',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'bother',\n",
       " 'bothering',\n",
       " 'bottom',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'bp',\n",
       " 'brain',\n",
       " 'brainless',\n",
       " 'brake',\n",
       " 'brand',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breaks',\n",
       " 'bred',\n",
       " 'breed',\n",
       " 'breeders',\n",
       " 'breeding',\n",
       " 'breeds',\n",
       " 'bret',\n",
       " 'brian',\n",
       " 'brief',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'bruno',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'bu',\n",
       " 'bucharest',\n",
       " 'buenos',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bullied',\n",
       " 'bullies',\n",
       " 'bulls',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busking',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buying',\n",
       " 'bye',\n",
       " 'cachaça',\n",
       " 'cadaver',\n",
       " 'cah',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cannot',\n",
       " 'canon',\n",
       " 'cant',\n",
       " 'canterbury',\n",
       " 'capital',\n",
       " 'captain',\n",
       " 'caption',\n",
       " 'captured',\n",
       " 'car',\n",
       " 'care',\n",
       " 'career',\n",
       " 'cares',\n",
       " 'carpenter',\n",
       " 'carried',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'category',\n",
       " 'cats',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'cedilla',\n",
       " 'cellpadding',\n",
       " 'cellspacing',\n",
       " 'celtic',\n",
       " 'censorship',\n",
       " 'census',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centuries',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'charge',\n",
       " 'charges',\n",
       " 'chart',\n",
       " 'chatting',\n",
       " 'chavez',\n",
       " 'chavo',\n",
       " 'che',\n",
       " 'cheated',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'cheers',\n",
       " 'chest',\n",
       " 'child',\n",
       " 'childcare',\n",
       " 'childish',\n",
       " 'childishly',\n",
       " 'children',\n",
       " 'chiliboy',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'christian',\n",
       " 'christianity',\n",
       " 'christians',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'circumstances',\n",
       " 'citadel',\n",
       " 'citation',\n",
       " 'citations',\n",
       " 'cite',\n",
       " 'cited',\n",
       " 'citing',\n",
       " 'citizens',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civilians',\n",
       " 'civility',\n",
       " 'claim',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clairsentience',\n",
       " 'clairvoyance',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classification',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'clicking',\n",
       " 'climate',\n",
       " 'climates',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cm',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'cold',\n",
       " 'colder',\n",
       " 'cole',\n",
       " 'collapse',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'color',\n",
       " 'column',\n",
       " 'columns',\n",
       " 'com',\n",
       " 'combating',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'comitted',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'common',\n",
       " 'commoners',\n",
       " 'commonly',\n",
       " 'commons',\n",
       " 'communicate',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'comply',\n",
       " 'compound',\n",
       " 'compromise',\n",
       " 'computer',\n",
       " 'conceal',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'conclusions',\n",
       " 'conditions',\n",
       " 'conduct',\n",
       " 'confederation',\n",
       " 'conference',\n",
       " 'confirmed',\n",
       " 'conflict',\n",
       " 'conform',\n",
       " 'confused',\n",
       " 'confusion',\n",
       " 'congress',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'consecrated',\n",
       " 'consecutive',\n",
       " 'consensus',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'constructive',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'content',\n",
       " 'contents',\n",
       " 'context',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuously',\n",
       " 'contradiction',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'contribs',\n",
       " 'contribute',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'contribution',\n",
       " 'contributions',\n",
       " 'contributors',\n",
       " 'control',\n",
       " 'controlling',\n",
       " 'controversial',\n",
       " 'controversy',\n",
       " 'controvertial',\n",
       " 'convention',\n",
       " 'conversation',\n",
       " 'conversion',\n",
       " 'convert',\n",
       " 'convex',\n",
       " 'convinced',\n",
       " 'cool',\n",
       " 'coordinate',\n",
       " 'copied',\n",
       " 'copy',\n",
       " 'copyright',\n",
       " 'copyrights',\n",
       " 'core',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'corrected',\n",
       " 'correctly',\n",
       " 'correctness',\n",
       " 'cos',\n",
       " 'could',\n",
       " 'coulter',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counted',\n",
       " 'counter',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'county',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'courtesy',\n",
       " 'cover',\n",
       " 'covering',\n",
       " 'coward',\n",
       " 'cp',\n",
       " 'crap',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creation',\n",
       " 'creature',\n",
       " 'credibility',\n",
       " 'credits',\n",
       " 'cricket',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'criticism',\n",
       " 'criticisms',\n",
       " 'cronies',\n",
       " 'cross',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'cunt',\n",
       " 'cuntliz',\n",
       " 'cup',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'currie',\n",
       " 'cursed',\n",
       " 'cut',\n",
       " 'cuz',\n",
       " 'cyber',\n",
       " 'cyberdyne',\n",
       " 'da',\n",
       " 'dabble',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'dahn',\n",
       " 'daily',\n",
       " 'damaged',\n",
       " 'damaging',\n",
       " 'damn',\n",
       " 'dan',\n",
       " 'dance',\n",
       " 'dangerous',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dates',\n",
       " 'david',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dean',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'debating',\n",
       " 'dec',\n",
       " 'decend',\n",
       " 'decended',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'declared',\n",
       " 'decline',\n",
       " 'declined',\n",
       " 'decorated',\n",
       " 'dedicated',\n",
       " 'deeply',\n",
       " 'defend',\n",
       " 'defending',\n",
       " 'defense',\n",
       " 'defined',\n",
       " 'defines',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'definitions',\n",
       " 'delanoy',\n",
       " 'delete',\n",
       " 'deleted',\n",
       " 'deleting',\n",
       " 'deletion',\n",
       " 'deletions',\n",
       " 'deliberately',\n",
       " 'delivered',\n",
       " 'democracy',\n",
       " 'democratic',\n",
       " 'demonstrate',\n",
       " 'demonstrating',\n",
       " 'denied',\n",
       " 'denomination',\n",
       " 'deny',\n",
       " 'depression',\n",
       " 'describe',\n",
       " 'described',\n",
       " 'describes',\n",
       " 'describing',\n",
       " 'description',\n",
       " 'descriptions',\n",
       " 'deserve',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'deserving',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'deter',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'detrimental',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'devil',\n",
       " 'devoted',\n",
       " 'dhis',\n",
       " 'dhoni',\n",
       " 'dick',\n",
       " 'dicks',\n",
       " 'dicono',\n",
       " 'dictionary',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'diff',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'differing',\n",
       " 'difficult',\n",
       " 'diffs',\n",
       " 'dikkkkk',\n",
       " 'diligence',\n",
       " 'direct',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
