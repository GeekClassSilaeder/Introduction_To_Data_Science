{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should_ban</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The picture on the article is not of the actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Its madness. Shes of Chinese heritage, but JAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck You. Why don't you suck a turd out of my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>God is dead\\r\\nI don't mean to startle anyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>THIS USER IS A PLANT FROM BRUCE PERENS AND GRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>rowspan=9 colspan=8|Did Not Qualify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>\"== Disputed and under-referenced ==\\r\\n\\r\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>Why?\\r\\nWhy does this event have its own page?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>Que? \\r\\n\\r\\nWas this fat fingers? If not,  ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>so everytime i reset my modem my ip changes\\r\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     should_ban                                       comment_text\n",
       "0             0  The picture on the article is not of the actor...\n",
       "1             1  Its madness. Shes of Chinese heritage, but JAP...\n",
       "2             1  Fuck You. Why don't you suck a turd out of my ...\n",
       "3             1  God is dead\\r\\nI don't mean to startle anyone ...\n",
       "4             1  THIS USER IS A PLANT FROM BRUCE PERENS AND GRO...\n",
       "..          ...                                                ...\n",
       "995           0                rowspan=9 colspan=8|Did Not Qualify\n",
       "996           0  \"== Disputed and under-referenced ==\\r\\n\\r\\nI ...\n",
       "997           0  Why?\\r\\nWhy does this event have its own page?...\n",
       "998           0  Que? \\r\\n\\r\\nWas this fat fingers? If not,  ca...\n",
       "999           1  so everytime i reset my modem my ip changes\\r\\...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"comments.tsv\", sep='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = TweetTokenizer()\n",
    "def preprocess(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = morph.parse(words[i])[0].normal_form\n",
    "    return ' '.join(words).lower()\n",
    "words = set(\" \".join(list(data.comment_text)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"comment_text\"] = data[\"comment_text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"comment_text\"]\n",
    "Y = data[\"should_ban\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(X_train)\n",
    "X_train = count_vect.transform(X_train)\n",
    "X_test = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tree\n",
      "0.8464811399354834\n",
      "0.6938225671948168\n",
      "\n",
      "forest\n",
      "1.0\n",
      "0.730450959009558\n",
      "\n",
      "boosting\n",
      "0.9131518418560268\n",
      "0.7942138687536083\n",
      "\n",
      "logistic\n",
      "1.0\n",
      "0.7900121880813396\n",
      "\n",
      "neigh\n",
      "0.8249186421608072\n",
      "0.6701520302777599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = {\n",
    "    'tree': DecisionTreeClassifier(max_depth=10),\n",
    "    'forest': RandomForestClassifier(n_jobs=-1),\n",
    "    'boosting': GradientBoostingClassifier(),\n",
    "    'logistic': LogisticRegression(),\n",
    "    'neigh': KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "}\n",
    "\n",
    "for i in models:\n",
    "    print('\\n' + i)\n",
    "    models[i].fit(X_train,y_train)\n",
    "    y_pred_train = models[i].predict(X_train)\n",
    "    y_pred_test = models[i].predict(X_test)\n",
    "#     print(accuracy_score(y_train,y_pred_train)) \n",
    "#     print(accuracy_score(y_test,y_pred_test))\n",
    "    print(roc_auc_score(y_train,y_pred_train)) \n",
    "    print(roc_auc_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF/IDF with stop words**   \n",
    "tree\n",
    "0.88783299745779\n",
    "0.7021617807428314\n",
    "\n",
    "forest\n",
    "1.0\n",
    "0.7052408749759446\n",
    "\n",
    "boosting\n",
    "0.938769769776898\n",
    "0.8117582911027007\n",
    "\n",
    "logistic\n",
    "0.9385810623161882\n",
    "0.7999230226441723\n",
    "\n",
    "neigh\n",
    "0.8723198199802036\n",
    "0.7464558342420938\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COUNT VECTORIZER with stop words**  \n",
    "tree\n",
    "0.8493333333333334\n",
    "0.696\n",
    "\n",
    "forest\n",
    "1.0\n",
    "0.692\n",
    "\n",
    "boosting\n",
    "0.9146666666666666\n",
    "0.792\n",
    "\n",
    "logistic\n",
    "1.0\n",
    "0.788\n",
    "\n",
    "neigh\n",
    "0.828\n",
    "0.664"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COUNT VECTORIZER without stop words**  \n",
    "tree\n",
    "0.7386666666666667\n",
    "0.6\n",
    "\n",
    "forest\n",
    "1.0\n",
    "0.76\n",
    "\n",
    "boosting\n",
    "0.9066666666666666\n",
    "0.72\n",
    "\n",
    "logistic\n",
    "0.9986666666666667\n",
    "0.764\n",
    "\n",
    "neigh\n",
    "0.7453333333333333\n",
    "0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF/IDF without stop_words**  \n",
    "tree\n",
    "0.7219057317220803\n",
    "0.6045288344345372\n",
    "\n",
    "forest\n",
    "1.0\n",
    "0.7700942972608891\n",
    "\n",
    "boosting\n",
    "0.9356009086442258\n",
    "0.7346526396818269\n",
    "\n",
    "logistic\n",
    "0.986747751532803\n",
    "0.7942138687536083\n",
    "\n",
    "neigh\n",
    "0.8650385604113111\n",
    "0.7101481814099685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучше всего TF/IDF без исключения стоп слов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
